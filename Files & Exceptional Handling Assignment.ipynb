{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b2bfca-cc69-46dc-a1c0-26313858f521",
   "metadata": {},
   "source": [
    "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
    "multiprocessing is a better choice.\n",
    "\n",
    "\n",
    "When deciding between **multithreading** and **multiprocessing** for a task, the key factors to consider are the type of workload, the need for parallelism, and how the system's resources (CPU, memory, etc.) will be utilized. Below are scenarios where each approach is preferable:\r\n",
    "\r\n",
    "### **Multithreading**:\r\n",
    "\r\n",
    "Multithreading is beneficial when a program needs to perform multiple tasks simultaneously but does not need to fully utilize the CPU, particularly when tasks are I/O-bound. It allows multiple threads to share the same memory space and is lightweight compared to multiprocessing.\r\n",
    "\r\n",
    "#### **Scenarios where multithreading is preferable**:\r\n",
    "1. **I/O-bound tasks**: If a program spends most of its time waiting for external operations (disk I/O, network requests, database access, etc.), using threads can be highly efficient since the CPU can switch between threads while one thread waits for I/O. Examples include:\r\n",
    "   - **Web servers**: Handling multiple incoming requests.\r\n",
    "   - **File I/O operations**: Reading/writing to files.\r\n",
    "   - **Network operations**: Managing multiple network connections like in a chat application.\r\n",
    "   \r\n",
    "2. **Low memory overhead**: Threads share the same memory space, so they are more lightweight than processes. This makes multithreading preferable in environments with limited memory where you want to minimize memory overhead.\r\n",
    "\r\n",
    "3. **Real-time responsiveness**: Multithreading is a good choice when the application needs to remain responsive to events, such as user interface (UI) applications that should remain interactive while performing background tasks.\r\n",
    "\r\n",
    "4. **Faster thread creation**: Thread creation is generally faster than process creation, making it more efficient when there’s a need to spawn many concurrent workers for short tasks.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Multiprocessing**:\r\n",
    "\r\n",
    "Multiprocessing is useful when tasks are CPU-bound and need to fully utilize multiple CPU cores. Each process runs in its own memory space, so there’s no need for locks to manage memory access, reducing concurrency issues like deadlocks.\r\n",
    "\r\n",
    "#### **Scenarios where multiprocessing is preferable**:\r\n",
    "1. **CPU-bound tasks**: Tasks that require heavy CPU computation (such as mathematical calculations, data processing, machine learning model training) benefit from multiprocessing because Python's Global Interpreter Lock (GIL) prevents true parallel execution of threads for CPU-bound tasks. Multiprocessing bypasses this limitation by running tasks in separate memory spaces on different CPU cores. Examples include:\r\n",
    "   - **Data processing**: Tasks like image processing, video rendering, or scientific simulations.\r\n",
    "   - **Parallel computation**: Distributing complex algorithms or simulations across multiple processors.\r\n",
    "\r\n",
    "2. **Isolated execution**: Since each process has its own memory space, multiprocessing is more robust in terms of memory safety, avoiding problems like race conditions, shared state issues, and deadlocks that arise with shared memory in multithreading.\r\n",
    "\r\n",
    "3. **Fault tolerance**: In multiprocessing, if one process crashes, it won’t affect the other processes because they don’t share memory. This isolation is beneficial when running multiple independent tasks that may fail independently.\r\n",
    "\r\n",
    "4. **Large tasks or memory-intensive jobs**: Since processes don’t share memory, they can use more memory without interfering with each other, making multiprocessing preferable when dealing with tasks that require a lot of memory.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Comparison Table**:\r\n",
    "\r\n",
    "| Scenario                        | Multithreading                       | Multiprocessing                     |\r\n",
    "|----------------------------------|--------------------------------------|-------------------------------------|\r\n",
    "| **I/O-bound tasks**              | ✅ Preferred (as threads can wait for I/O) | ❌ Not ideal |\r\n",
    "| **CPU-bound tasks**              | ❌ Not ideal (due to GIL)             | ✅ Preferred (can utilize multiple cores) |\r\n",
    "| **Memory usage**                 | ✅ Lower (shared memory)             | ❌ Higher (separate memory space)   |\r\n",
    "| **Task isolation**               | ❌ Less isolated (shared memory)     | ✅ More isolated (separate memory) |\r\n",
    "| **Creation time**                | ✅ Faster (lightweight)              | ❌ Slower (heavier due to process creation) |\r\n",
    "| **Concurrency safety**           | ❌ Risk of race conditions, deadlocks | ✅ Better due to isolated memory   |\r\n",
    "| **Fault tolerance**              | ❌ A thread crash may affect others  | ✅ Crashes are isolated             |\r\n",
    "\r\n",
    "### Conclusion:\r\n",
    "- Use **multithreading** when tasks are I/O-bound or when there is a need for lightweight concurrency.\r\n",
    "- Use **multiprocessing** when tasks are CPU-bound and can benefit from true parallelism across multiple CPU cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00161398-f18c-4b1c-b9a2-5f0670368e92",
   "metadata": {},
   "source": [
    "2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "A **process pool** is a collection of worker processes that are pre-created and managed for executing tasks in parallel. It helps manage multiple processes efficiently by reusing the same processes for different tasks, which reduces the overhead of creating and destroying processes repeatedly. This allows for better utilization of system resources like CPU and memory, provides automatic task distribution among workers, and simplifies concurrent execution. The pool also limits the number of active processes, preventing system overload and ensuring efficient parallelization for CPU-bound tasks."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b27ca3b-2307-49ef-b464-c42060327bf6",
   "metadata": {},
   "source": [
    "3. Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "**Multiprocessing** in Python refers to the ability to run multiple processes simultaneously to perform parallel tasks, particularly for CPU-bound operations. Each process runs independently with its own memory space and Python interpreter, allowing them to execute truly in parallel across multiple CPU cores.\n",
    "\n",
    "### **Why Multiprocessing is Used in Python**:\n",
    "1. **Bypassing the Global Interpreter Lock (GIL)**: Python’s **GIL** restricts the execution of multiple threads in parallel for CPU-bound tasks. Multiprocessing bypasses this limitation by using separate processes, enabling true parallelism.\n",
    "   \n",
    "2. **Efficient Use of Multiple Cores**: Modern CPUs have multiple cores. Multiprocessing allows Python programs to distribute tasks across these cores, improving performance for CPU-intensive tasks like data processing, scientific computations, or machine learning.\n",
    "\n",
    "3. **Fault Isolation**: Since each process has its own memory space, if one process crashes, it doesn’t affect others, making multiprocessing safer for certain applications compared to multithreading.\n",
    "\n",
    "Overall, **multiprocessing** is used to improve performance, scalability, and efficiency in programs where tasks can be divided into independent, parallel processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee6814-86ae-4dbd-a3f8-2b49896a2be3",
   "metadata": {},
   "source": [
    "4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
    "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
    "threading.Lock.\n",
    "\n",
    "Here is a Python program using **multithreading** where one thread adds numbers to a list and another thread removes numbers from the list. A `threading.Lock` is used to avoid race conditions, ensuring that the list operations (adding and removing) are performed safely without interference from other threads.\n",
    "\n",
    "```python\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared resource (list)\n",
    "numbers_list = []\n",
    "\n",
    "# Create a lock object\n",
    "list_lock = threading.Lock()\n",
    "\n",
    "# Function for adding numbers to the list\n",
    "def add_to_list():\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(1)  # Simulate some delay\n",
    "        # Acquire the lock before modifying the shared resource\n",
    "        with list_lock:\n",
    "            numbers_list.append(i)\n",
    "            print(f\"Added {i} to the list. Current list: {numbers_list}\")\n",
    "\n",
    "# Function for removing numbers from the list\n",
    "def remove_from_list():\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(1.5)  # Simulate some delay\n",
    "        # Acquire the lock before modifying the shared resource\n",
    "        with list_lock:\n",
    "            if numbers_list:\n",
    "                removed_item = numbers_list.pop(0)\n",
    "                print(f\"Removed {removed_item} from the list. Current list: {numbers_list}\")\n",
    "            else:\n",
    "                print(\"List is empty, cannot remove.\")\n",
    "\n",
    "# Create threads for adding and removing\n",
    "add_thread = threading.Thread(target=add_to_list)\n",
    "remove_thread = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Start the threads\n",
    "add_thread.start()\n",
    "remove_thread.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "add_thread.join()\n",
    "remove_thread.join()\n",
    "\n",
    "print(\"Final list:\", numbers_list)\n",
    "```\n",
    "\n",
    "### **How the Program Works**:\n",
    "1. **Shared Resource**: `numbers_list` is the list shared between the two threads.\n",
    "2. **Threading.Lock**: A lock (`list_lock`) is used to ensure that only one thread modifies the list at a time, preventing race conditions.\n",
    "3. **Thread 1 (Adding)**: Adds numbers from 1 to 5 to the list with a delay of 1 second between each addition.\n",
    "4. **Thread 2 (Removing)**: Removes the first element of the list with a delay of 1.5 seconds, making sure to check if the list is non-empty.\n",
    "5. **Locking Mechanism**: The `with list_lock:` block ensures that both adding and removing operations are performed atomically, avoiding simultaneous modifications to the list.\n",
    "\n",
    "### **Output**:\n",
    "You will see numbers being added and removed sequentially, ensuring no race condition occurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36e903-d859-44e9-9756-4715ec827a69",
   "metadata": {},
   "source": [
    "5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
    "processes.\n",
    "\n",
    "In Python, safely sharing data between threads and processes is crucial to avoid race conditions and ensure data consistency. Different methods and tools are used for thread-safe and process-safe communication. Below is a breakdown of the available mechanisms:\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **For Threads**:\r\n",
    "Since threads share the same memory space, race conditions can occur when multiple threads access or modify shared data simultaneously. Python provides various synchronization mechanisms to ensure thread-safe data sharing.\r\n",
    "\r\n",
    "#### **1. Threading Locks (Mutex)**:\r\n",
    "- **`threading.Lock`**: A basic locking mechanism that ensures only one thread can access a critical section of code at a time.\r\n",
    "- When one thread acquires the lock, other threads trying to acquire it will be blocked until the lock is released.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   import threading\r\n",
    "   \r\n",
    "   lock = threading.Lock()\r\n",
    "   \r\n",
    "   # Critical section\r\n",
    "   with lock:\r\n",
    "       # Safe access to shared data\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **2. RLock (Reentrant Lock)**:\r\n",
    "- **`threading.RLock`**: A lock that allows the same thread to acquire it multiple times without getting blocked, useful when a thread needs to re-enter a critical section.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   lock = threading.RLock()\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **3. Condition Variables**:\r\n",
    "- **`threading.Condition`**: Combines a lock with a wait/notify mechanism. Threads can wait for a certain condition to be met and be notified when other threads modify shared data.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   condition = threading.Condition()\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **4. Semaphore**:\r\n",
    "- **`threading.Semaphore`**: A semaphore limits the number of threads that can access a shared resource concurrently. It can be used when a resource can be accessed by a fixed number of threads at the same time.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   semaphore = threading.Semaphore(value=3)\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **5. Queue**:\r\n",
    "- **`queue.Queue`**: A thread-safe FIFO queue for safely sharing data between threads. It handles locking internally, so you don’t need to manage locks yourself.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   import queue\r\n",
    "   \r\n",
    "   q = queue.Queue()\r\n",
    "   q.put(item)  # Add item to the queue\r\n",
    "   item = q.get()  # Retrieve item from the queue\r\n",
    "   ```\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **For Processes**:\r\n",
    "Since processes have separate memory spaces, data cannot be shared directly between them. Python provides several tools and mechanisms for safe data sharing between processes.\r\n",
    "\r\n",
    "#### **1. Multiprocessing Manager**:\r\n",
    "- **`multiprocessing.Manager`**: Provides shared objects like lists, dictionaries, and more that can be safely shared and modified between processes.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   from multiprocessing import Manager\r\n",
    "   \r\n",
    "   manager = Manager()\r\n",
    "   shared_list = manager.list()\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **2. Multiprocessing Queue**:\r\n",
    "- **`multiprocessing.Queue`**: A thread-safe and process-safe FIFO queue for passing data between processes. Processes can safely put and get items from the queue.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   from multiprocessing import Queue\r\n",
    "   \r\n",
    "   q = Queue()\r\n",
    "   q.put(item)  # Add item\r\n",
    "   item = q.get()  # Retrieve item\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **3. Shared Memory (Value, Array)**:\r\n",
    "- **`multiprocessing.Value`** and **`multiprocessing.Array`**: Allow data to be shared between processes via shared memory. `Value` shares a single variable, and `Array` shares a list-like structure.\r\n",
    "\r\n",
    "   ```python\r\n",
    "   from multiprocessing import Value, Array\r\n",
    "   \r\n",
    "   shared_value = Value('i', 0)  # 'i' for integer\r\n",
    "   shared_array = Array('i', [1, 2, 3])  # 'i' for integer array\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **4. Pipe**:\r\n",
    "- **`multiprocessing.Pipe`**: Creates a two-way communication channel between processes. It can be used for bidirectional communication, allowing two processes to send and receive data.\r\n",
    "  \r\n",
    "   ```python\r\n",
    "   from multiprocessing import Pipe\r\n",
    "   \r\n",
    "   parent_conn, child_conn = Pipe()\r\n",
    "   parent_conn.send(data)\r\n",
    "   received = child_conn.recv()\r\n",
    "   ```\r\n",
    "\r\n",
    "#### **5. Lock**:\r\n",
    "- **`multiprocessing.Lock`**: A lock that prevents multiple processes from modifying shared data at the same time. It works similarly to `threading.Lock` but for processes.\r\n",
    "\r\n",
    "   ```python\r\n",
    "   from multiprocessing import Lock\r\n",
    "   \r\n",
    "   lock = Lock()\r\n",
    "   with lock:\r\n",
    "       # Critical section for process-safe access\r\n",
    "   ```\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Summary Table**:\r\n",
    "\r\n",
    "| **Mechanism**              | **For Threads**                                 | **For Processes**                               |\r\n",
    "|----------------------------|-------------------------------------------------|------------------------------------------------|\r\n",
    "| **Lock**                   | `threading.Lock`                                | `multiprocessing.Lock`                         |\r\n",
    "| **Reentrant Lock (RLock)**  | `threading.RLock`                               | `multiprocessing.RLock` (rarely used)          |\r\n",
    "| **Condition Variables**     | `threading.Condition`                           | `multiprocessing.Condition`                    |\r\n",
    "| **Semaphore**               | `threading.Semaphore`                           | `multiprocessing.Semaphore`                    |\r\n",
    "| **Queue**                   | `queue.Queue` (thread-safe)                     | `multiprocessing.Queue` (process-safe)         |\r\n",
    "| **Shared Memory**           | N/A                                             | `multiprocessing.Value`, `multiprocessing.Array` |\r\n",
    "| **Manager**                 | N/A                                             | `multiprocessing.Manager`                      |\r\n",
    "| **Pipe**                    | N/A                                             | `multiprocessing.Pipe`                         |\r\n",
    "\r\n",
    "### **Conclusion**:\r\n",
    "In Python, threads share memory, so synchronization tools like locks and queues are used to avoid race conditions. For processes, shared memory, queues, and pipes are employed since processes do not share memory space. These tools ensure safe communication and data handling across multiple threads or processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4093a47a-2399-4eeb-a2ac-3a5681c9d2fc",
   "metadata": {},
   "source": [
    "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
    "doing so.\n",
    "                                                                                                    \n",
    "Handling exceptions in concurrent programs (whether multithreaded or multiprocessed) is crucial because errors in one thread or process can lead to inconsistent program states, crashes, or resource leaks. Without proper exception handling, concurrency-related issues like deadlocks, data corruption, and unhandled crashes can occur, leading to unpredictable behavior. Here’s why and how to handle exceptions effectively in concurrent programs:\n",
    "\n",
    "### **Why Exception Handling is Crucial in Concurrent Programs**:\n",
    "1. **Avoid Crashes and Inconsistent States**:\n",
    "   - In a multithreaded or multiprocessed environment, an unhandled exception in one thread or process can crash that specific task. If other threads or processes depend on shared resources (memory, files, etc.), this can leave those resources in an inconsistent or corrupt state.\n",
    "   \n",
    "2. **Ensuring Thread/Process Safety**:\n",
    "   - Failure in one thread or process can affect the overall application’s stability if resources (like locks, files, or network connections) are left in an unusable or locked state.\n",
    "\n",
    "3. **Resource Management**:\n",
    "   - Without proper exception handling, resources like memory, file handles, or network connections might not be released, causing resource leaks. This can lead to performance degradation or crashes, especially in long-running applications.\n",
    "\n",
    "4. **Debugging and Error Tracking**:\n",
    "   - If exceptions in concurrent programs are not handled properly, they may go unnoticed or be hard to trace, making debugging difficult. Centralized exception handling helps capture and log errors for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Techniques for Handling Exceptions in Concurrent Programs**:\n",
    "\n",
    "#### **1. Exception Handling in Threads**:\n",
    "In Python, exceptions in threads do not automatically propagate to the main thread. However, they can be handled using the following techniques:\n",
    "\n",
    "##### **Try-Except Blocks**:\n",
    "- Each thread can handle exceptions individually using try-except blocks to catch errors and take corrective action.\n",
    "  \n",
    "   ```python\n",
    "   import threading\n",
    "   \n",
    "   def thread_task():\n",
    "       try:\n",
    "           # Code that may raise an exception\n",
    "           risky_operation()\n",
    "       except Exception as e:\n",
    "           print(f\"Exception in thread: {e}\")\n",
    "   \n",
    "   t = threading.Thread(target=thread_task)\n",
    "   t.start()\n",
    "   t.join()\n",
    "   ```\n",
    "\n",
    "##### **Using Custom Exception Propagation**:\n",
    "- To propagate exceptions to the main thread or handle them centrally, you can catch exceptions in the thread, store them, and re-raise them in the main thread after the thread has finished.\n",
    "  \n",
    "   ```python\n",
    "   import threading\n",
    "   \n",
    "   def thread_task(exception_list):\n",
    "       try:\n",
    "           # Risky operation\n",
    "           risky_operation()\n",
    "       except Exception as e:\n",
    "           exception_list.append(e)\n",
    "   \n",
    "   exceptions = []\n",
    "   t = threading.Thread(target=thread_task, args=(exceptions,))\n",
    "   t.start()\n",
    "   t.join()\n",
    "   \n",
    "   if exceptions:\n",
    "       raise exceptions[0]  # Propagate the exception to the main thread\n",
    "   ```\n",
    "\n",
    "##### **Threading with `concurrent.futures.ThreadPoolExecutor`**:\n",
    "- The `concurrent.futures.ThreadPoolExecutor` provides a way to handle exceptions in threads more gracefully. It allows you to retrieve the result of a thread (future object) and capture any exceptions that occurred.\n",
    "  \n",
    "   ```python\n",
    "   from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "   \n",
    "   def risky_operation():\n",
    "       # Code that may fail\n",
    "       raise ValueError(\"Something went wrong in thread\")\n",
    "   \n",
    "   with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "       future = executor.submit(risky_operation)\n",
    "       try:\n",
    "           result = future.result()  # This will raise the exception\n",
    "       except Exception as e:\n",
    "           print(f\"Exception caught: {e}\")\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Exception Handling in Processes**:\n",
    "In Python’s multiprocessing, each process runs independently, and exceptions do not propagate to the parent process. Handling exceptions in multiprocessing requires explicit techniques:\n",
    "\n",
    "##### **Try-Except Blocks**:\n",
    "- As with threads, you can use try-except blocks within each process to catch and handle exceptions locally.\n",
    "  \n",
    "   ```python\n",
    "   from multiprocessing import Process\n",
    "   \n",
    "   def process_task():\n",
    "       try:\n",
    "           risky_operation()\n",
    "       except Exception as e:\n",
    "           print(f\"Exception in process: {e}\")\n",
    "   \n",
    "   p = Process(target=process_task)\n",
    "   p.start()\n",
    "   p.join()\n",
    "   ```\n",
    "\n",
    "##### **Multiprocessing with `concurrent.futures.ProcessPoolExecutor`**:\n",
    "- Similar to `ThreadPoolExecutor`, `ProcessPoolExecutor` also allows exception handling via future objects. You can retrieve the result of a process and capture any exception raised during execution.\n",
    "  \n",
    "   ```python\n",
    "   from concurrent.futures import ProcessPoolExecutor\n",
    "   \n",
    "   def risky_operation():\n",
    "       raise ValueError(\"Error in process\")\n",
    "   \n",
    "   with ProcessPoolExecutor(max_workers=2) as executor:\n",
    "       future = executor.submit(risky_operation)\n",
    "       try:\n",
    "           result = future.result()  # This will raise the exception\n",
    "       except Exception as e:\n",
    "           print(f\"Process exception caught: {e}\")\n",
    "   ```\n",
    "\n",
    "##### **Handling Exceptions with Queues**:\n",
    "- For process communication, you can use a queue to pass exceptions back to the parent process.\n",
    "  \n",
    "   ```python\n",
    "   from multiprocessing import Process, Queue\n",
    "   \n",
    "   def process_task(q):\n",
    "       try:\n",
    "           risky_operation()\n",
    "       except Exception as e:\n",
    "           q.put(e)  # Put exception in queue\n",
    "   \n",
    "   q = Queue()\n",
    "   p = Process(target=process_task, args=(q,))\n",
    "   p.start()\n",
    "   p.join()\n",
    "   \n",
    "   if not q.empty():\n",
    "       exception = q.get()\n",
    "       print(f\"Exception caught from process: {exception}\")\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. General Techniques for Handling Exceptions in Concurrent Programs**:\n",
    "\n",
    "##### **1. Logging**:\n",
    "- Use a logging mechanism to track exceptions in threads or processes. This makes it easier to debug and trace errors across multiple workers.\n",
    "\n",
    "   ```python\n",
    "   import logging\n",
    "   logging.basicConfig(level=logging.ERROR)\n",
    "   \n",
    "   try:\n",
    "       risky_operation()\n",
    "   except Exception as e:\n",
    "       logging.error(\"Error occurred\", exc_info=True)\n",
    "   ```\n",
    "\n",
    "##### **2. Using `finally` for Resource Cleanup**:\n",
    "- Use the `finally` block to ensure resources (like locks, files, network connections) are properly released or closed, even if an exception occurs.\n",
    "  \n",
    "   ```python\n",
    "   lock.acquire()\n",
    "   try:\n",
    "       # Critical section\n",
    "   finally:\n",
    "       lock.release()  # Ensure lock is released even if an error occurs\n",
    "   ```\n",
    "\n",
    "##### **3. Timeouts**:\n",
    "- Use timeouts with threads and processes to prevent them from hanging indefinitely in case of errors or deadlocks.\n",
    "\n",
    "   ```python\n",
    "   p = Process(target=process_task)\n",
    "   p.start()\n",
    "   p.join(timeout=5)  # Wait for up to 5 seconds\n",
    "   if p.is_alive():\n",
    "       p.terminate()  # Terminate if the process hangs\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**:\n",
    "Handling exceptions in concurrent programs is essential to avoid crashes, resource leaks, and data corruption. Techniques like using try-except blocks, logging, using `concurrent.futures`, propagating exceptions through shared objects like queues, and employing timeouts help ensure stability, make debugging easier, and allow programs to handle errors gracefully across multiple threads or processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d59ccac-a1c0-4a87-98a3-667289896799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 8 is 40320\n",
      "Factorial of 1 is 1\n",
      "Factorial of 6 is 720\n",
      "Factorial of 3 is 6\n",
      "Factorial of 5 is 120\n",
      "Factorial of 4 is 24\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 2 is 2\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
    "#Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import math\n",
    "\n",
    "# Function to calculate the factorial of a number\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# Main block to execute concurrent calculations\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = list(range(1, 11))  # List of numbers from 1 to 10\n",
    "\n",
    "    # Create a ThreadPoolExecutor to manage threads\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit tasks to the thread pool\n",
    "        futures = {executor.submit(factorial, num): num for num in numbers}\n",
    "        \n",
    "        # Collect the results as they complete\n",
    "        for future in as_completed(futures):\n",
    "            num = futures[future]  # Get the number for which the factorial was calculated\n",
    "            try:\n",
    "                result = future.result()  # Get the result of the factorial calculation\n",
    "                print(f\"Factorial of {num} is {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating factorial for {num}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001795f1-10f1-4c69-87d1-cb14dc490a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
    "#parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
    "#processes\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def compute_square(n):\n",
    "    return n * n\n",
    "\n",
    "# Function to compute squares in parallel using a Pool\n",
    "def compute_squares_with_pool(pool_size):\n",
    "    numbers = list(range(1, 11))  # List of numbers from 1 to 10\n",
    "    print(f\"\\nUsing pool size: {pool_size}\")\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a Pool with the specified number of processes\n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        # Map the compute_square function across the numbers list\n",
    "        results = pool.map(compute_square, numbers)\n",
    "\n",
    "    # End the timer\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print the results and the time taken\n",
    "    print(f\"Squares: {results}\")\n",
    "    print(f\"Time taken with pool size {pool_size}: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the computation with different pool sizes\n",
    "    for pool_size in [2, 4, 8]:\n",
    "        compute_squares_with_pool(pool_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f481f96-017d-4fe9-90af-dcfffd58f964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ae398-345f-4458-94ab-38885d2cce29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
